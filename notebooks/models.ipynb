{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":5,"outputs":[{"output_type":"stream","text":"/kaggle/input/rule-based-model2/email_labelled.csv\n/kaggle/input/rule-based-model2/eamil_labelled.csv\n/kaggle/input/rule-based-model2/custom.css\n/kaggle/input/rule-based-model2/__notebook__.ipynb\n/kaggle/input/rule-based-model2/__results__.html\n/kaggle/input/rule-based-model2/__output__.json\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/rule-based-model2/eamil_labelled.csv\")","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text']=df[\"text\"].map(lambda x:x.replace('\"',''))","execution_count":42,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['text'],df['target'],stratify=df['target'],test_size=0.20, random_state=42)","execution_count":94,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer","execution_count":103,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\ntext_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', MultinomialNB()), ])\ntext_clf.fit(X_train,y_train)\nprint(\"Model : Naive Bayes\")\nprint(\"Train : \", classification_report(y_train,text_clf.predict(X_train)))\nprint(\"Validation : \", classification_report(y_test,text_clf.predict(X_test)))\n#joblib.dump(pipeline, 'model.joblib')\n","execution_count":101,"outputs":[{"output_type":"stream","text":"Model : Naive Bayes\nTrain :                precision    recall  f1-score   support\n\n           0       0.93      0.98      0.96      2161\n           1       0.96      0.83      0.89      1000\n\n    accuracy                           0.94      3161\n   macro avg       0.94      0.91      0.92      3161\nweighted avg       0.94      0.94      0.94      3161\n\nValidation :                precision    recall  f1-score   support\n\n           0       0.84      0.97      0.90       541\n           1       0.91      0.60      0.73       250\n\n    accuracy                           0.86       791\n   macro avg       0.88      0.79      0.81       791\nweighted avg       0.86      0.86      0.85       791\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\ntext_clf = Pipeline([ ('vect', CountVectorizer()),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n                                           alpha=1e-3, random_state=42,                           \n                                           max_iter=5, tol=None)),])\ntext_clf.fit(X_train,y_train)\nprint(\"Model : SVM\")\nprint(\"Train : \", classification_report(y_train,text_clf.predict(X_train)))\nprint(\"Validation : \", classification_report(y_test,text_clf.predict(X_test)))\n","execution_count":102,"outputs":[{"output_type":"stream","text":"Model : SVM\nTrain :                precision    recall  f1-score   support\n\n           0       0.92      0.97      0.94      2161\n           1       0.92      0.81      0.86      1000\n\n    accuracy                           0.92      3161\n   macro avg       0.92      0.89      0.90      3161\nweighted avg       0.92      0.92      0.92      3161\n\nValidation :                precision    recall  f1-score   support\n\n           0       0.90      0.95      0.93       541\n           1       0.88      0.77      0.82       250\n\n    accuracy                           0.90       791\n   macro avg       0.89      0.86      0.87       791\nweighted avg       0.89      0.90      0.89       791\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\ntext_clf = Pipeline([ ('vect', CountVectorizer()),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', LogisticRegression()),])\ntext_clf.fit(X_train,y_train)\nprint(\"Model : SVM\")\nprint(\"Train : \", classification_report(y_train,text_clf.predict(X_train)))\nprint(\"Validation : \", classification_report(y_test,text_clf.predict(X_test)))\n","execution_count":106,"outputs":[{"output_type":"stream","text":"Model : SVM\nTrain :                precision    recall  f1-score   support\n\n           0       0.92      0.98      0.94      2161\n           1       0.94      0.81      0.87      1000\n\n    accuracy                           0.92      3161\n   macro avg       0.93      0.89      0.91      3161\nweighted avg       0.92      0.92      0.92      3161\n\nValidation :                precision    recall  f1-score   support\n\n           0       0.90      0.96      0.93       541\n           1       0.89      0.76      0.82       250\n\n    accuracy                           0.90       791\n   macro avg       0.90      0.86      0.87       791\nweighted avg       0.90      0.90      0.89       791\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# LSTM Model"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 5000 \nembedding_dim = 64\nmax_length = 200\ntrunc_type = 'post'\npadding_type = 'post'\noov_tok = '<OOV>' \ntraining_portion = .8","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(df['text'])\nword_index = tokenizer.word_index","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sequences = tokenizer.texts_to_sequences(X_train)\ntrain_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\nvalid_sequences = tokenizer.texts_to_sequences(X_test)\nvalid_padded = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)","execution_count":109,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = tf.keras.utils.to_categorical(\n    y_train, num_classes=2, dtype='float32')\n\nvalid_labels = tf.keras.utils.to_categorical(y_test,\n                                            num_classes=2,\n                                            dtype=\"float32\")","execution_count":110,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Embedding(vocab_size, embedding_dim))\nmodel.add(Dropout(0.5))\nmodel.add(Bidirectional(LSTM(embedding_dim)))\nmodel.add(Dense(2, activation='sigmoid'))\n\nmodel.summary()","execution_count":111,"outputs":[{"output_type":"stream","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_4 (Embedding)      (None, None, 64)          320000    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, None, 64)          0         \n_________________________________________________________________\nbidirectional_4 (Bidirection (None, 128)               66048     \n_________________________________________________________________\ndense_4 (Dense)              (None, 2)                 258       \n=================================================================\nTotal params: 386,306\nTrainable params: 386,306\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy'],\n)","execution_count":112,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nhistory = model.fit(train_padded, train_labels, \n                    epochs=num_epochs, \n                    validation_data=(valid_padded, valid_labels), \n                    verbose=2)","execution_count":114,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n99/99 - 14s - loss: 0.5101 - accuracy: 0.7612 - val_loss: 0.3372 - val_accuracy: 0.8799\nEpoch 2/10\n99/99 - 13s - loss: 0.2334 - accuracy: 0.9117 - val_loss: 0.2208 - val_accuracy: 0.9178\nEpoch 3/10\n99/99 - 14s - loss: 0.1460 - accuracy: 0.9478 - val_loss: 0.2219 - val_accuracy: 0.9102\nEpoch 4/10\n99/99 - 14s - loss: 0.0962 - accuracy: 0.9665 - val_loss: 0.2144 - val_accuracy: 0.9166\nEpoch 5/10\n99/99 - 14s - loss: 0.0629 - accuracy: 0.9801 - val_loss: 0.2511 - val_accuracy: 0.9128\nEpoch 6/10\n99/99 - 13s - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.2443 - val_accuracy: 0.9166\nEpoch 7/10\n99/99 - 14s - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.2909 - val_accuracy: 0.9027\nEpoch 8/10\n99/99 - 14s - loss: 0.0283 - accuracy: 0.9918 - val_loss: 0.2975 - val_accuracy: 0.9064\nEpoch 9/10\n99/99 - 14s - loss: 0.0684 - accuracy: 0.9750 - val_loss: 0.2829 - val_accuracy: 0.8938\nEpoch 10/10\n99/99 - 14s - loss: 0.0871 - accuracy: 0.9737 - val_loss: 0.2798 - val_accuracy: 0.8951\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_train,model.predict_classes(train_padded)))","execution_count":117,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      2161\n           1       0.97      0.99      0.98      1000\n\n    accuracy                           0.99      3161\n   macro avg       0.98      0.99      0.99      3161\nweighted avg       0.99      0.99      0.99      3161\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,model.predict_classes(valid_padded)))","execution_count":118,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.93      0.91      0.92       541\n           1       0.82      0.86      0.84       250\n\n    accuracy                           0.90       791\n   macro avg       0.88      0.88      0.88       791\nweighted avg       0.90      0.90      0.90       791\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}